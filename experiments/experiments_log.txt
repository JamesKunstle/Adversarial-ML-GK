000-test-experiment.py:
    This is an example of the way that details about an experiment should be formatted.
    One indent after naming the experiment file is sufficient. 
    If your experiment requires its own subdirectory, please list the experiment number
    followed by the subdirectory name sans ".py"


001-cam-confusion-matrix.py:
    This experiment uses the simple classification model found in 'cam_simplenet_model.py'. 
    Using that simple NN that classifies the Fashion MNIST dataset with around 80% accuracy,
    the experiment first generates a confusion matrix outlining how the model performs in classification,
    and where it tends to misclassify certain ground truth classes. 

    Next, the experiment generates a similar matrix that I call the perturbation matrix -
    similar in concept to a confusion matrix but it instead has values of: 
    row = true label index, column = model predict index on the perturbed image.
    These perturbations are generated by the SimBA implemented previously by James Kunstle.

    Finally, this experiment builds perturbation heatmaps and displays them - these are built per class.
    The experiment runs SimBA again on all test data, and then aggregates the perturbations generated per 
    ground truth class into one perturbation heatmap per class, which displays the aggregated frequencies of
    where perturbations were created when making a misclassified image.


002-cam-gaussian-normal.py:
    Initial note: this experiment performs best (with plotting) when split up in a notebook.
    However, the python file will still run fine.

    This experiment uses the simple classification model found in 'cam_simplenet_model.py'. 
    Using that simple NN that classifies the Fashion MNIST dataset with around 80% accuracy,
    the experiment generates a confusion matrix outlining how the model performs in classifying 
    images that had gaussian noise applied to every pixel. As you can see in the matrix generated,
    the model performs well on images affected with gaussian noise.

    Next, I tried to create random perturbations in a centered distribution of the image. 
    This was just due to my intuition, that those areas would be more important for generating 
    effective perturbations. Here you can see the different parameters I tried: number of indexes I accessed,
    deltas (change to those pixel values). I tried several different values for both, but the results 
    were not very effective. 

003-cam-shapley-0.ipynb:
    Note that this is a notebook file not a python file as I was previously uploading!

    This experiment uses a CNN model trained in 'cam_training_fashion_mnist_cnn.ipynb' and stored as 
    'mnist_fashion_CNN.pt' in the models folder. With the CNN and the Fashion MNist dataset it is trained on, 
    we generate shapley values for a test set of only pants images using the shap python module.

    From there, a heatmap of the shapley values corresponding to the pants class is generated, and used to 
    generate perturbations in the locations of the X highest pixel locations of aggregated shapley values. 
    The model is then tested to see how it performs on the various perturbed images.

    Later, perturbations were generated inthe locations of X random pixel locations, to provide a benchmark to 
    compare the previous results to. The random pixel locations performed better.

004-cam-shapley-1.ipynb:
    This experiment uses a CNN model trained in 'cam_training_fashion_mnist_cnn.ipynb' and stored as 
    'mnist_fashion_CNN.pt' in the models folder. With the CNN and the Fashion MNist dataset it is trained on, 
    we generate shapley values for a test set of only pants images using the shap python module.
    
    From there, a heatmap of the shapley values corresponding to the pants class is generated, and used to 
    generate perturbations in the locations of the X LOWEST pixel locations of aggregated shapley values. 
    The model is then tested to see how it performs on the various perturbed images.

005-cam-shapley-2.ipynb:
    This experiment uses a CNN model trained in 'cam_training_fashion_mnist_cnn.ipynb' and stored as 
    'mnist_fashion_CNN.pt' in the models folder. With the CNN and the Fashion MNist dataset it is trained on, 
    we generate shapley values for a test set of only pants images using the shap python module.
    
    From there, a heatmap of the shapley values corresponding to the SNEAKERS class is generated, and used to 
    generate perturbations in the locations of the X highest pixel locations of aggregated shapley values. 
    The model is then tested to see how it performs on the various perturbed images.